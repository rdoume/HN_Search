{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trending searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to explore if we can get a way to get in a simple manner, the trending search of a day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we saw during the exploration, is that some query such as python, are queried everyday. On the opposite, the query 'tes' was trending on the 14th of june but was not requested at all for the next month."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is important, as we can have a better grasp of what is happening on a day, but was not happening before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import numpy as np\n",
    "import json\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "cf.set_config_file(offline=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "garbage=[]\n",
    "df=[]\n",
    "with open('./all.txt',encoding='utf-8',errors='ignore') as fp:\n",
    "    test= fp.readlines()\n",
    "for i,query in enumerate(test):\n",
    "    try:\n",
    "        df.append(json.loads(query.strip('\\n')))\n",
    "    except json.decoder.JSONDecodeError:\n",
    "        garbage.append(query)\n",
    "df=pd.DataFrame(df)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp']=pd.to_datetime(df['timestamp'])\n",
    "df.sort_index(inplace=True)\n",
    "df.set_index('timestamp',inplace=True)\n",
    "# We create a dataframe with just the query, and timestamp as index\n",
    "df_query=pd.DataFrame(df['query'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query=df_query[~(df_query['query']=='')] # We delete the empty queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the trending query per day, we start by resampling the previous dataframe on a daily basis, and grouping them together as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_perday=df_query.resample('1D').apply(list)\n",
    "df_query_perday.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have now to properly define what is a trending query.\n",
    "First of all,to be trending a query must be among the most requested.\n",
    "But to be trending, a query must not be among the most requested everyday.\n",
    "\n",
    "In this light, this is actually similar to what the TF-IDF score is in information retrieval.\n",
    "Briefly the TF-IDF stands for Term Frequency - Inverse document frequency, and is a score to determine how important a word is to a document in a  corpus of documents.\n",
    "\n",
    "If we turn we consider each day as a single \"document\", by resampling our dataframe on a daily basis, we actually created a corpus.\n",
    "\n",
    "We can then calculate the \"Term Frequency\", by counting each queries.\n",
    "\n",
    "Let's look for search that are trending on a day, but not within the 3 days prior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_perday['counted']=df_query_perday['query'].apply(lambda x: collections.Counter(x).most_common())\n",
    "df_query_perday.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a list of tuples, with the query and the number of occurences that day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_perday['counted']=df_query_pertimeframe['query'].apply(lambda x: collections.Counter(x).most_common())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to reduce computation cost, we will only focus on the N top queries per days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=1000 # we choose the top 1000 query here\n",
    "dfs=[]\n",
    "for day in df_query_perday.index:\n",
    "    dfs.append(pd.DataFrame.from_records(df_query_perday.loc[day].counted[0:N],columns=['searchq' ,'count']).set_index('searchq'))\n",
    "df_days = pd.concat(dfs,axis=1,sort=True)\n",
    "df_days['idf']=np.log10(len(dfs)/df_days.count(axis='columns'))\n",
    "# Let's calculate the trending queries of the last day of the data\n",
    "last_day=dfs[-1] \n",
    "last_day['tf'] = last_day / last_day.sum() \n",
    "last_day['idf']=df_days[\"idf\"]\n",
    "last_day['tfidf'] = last_day['idf'] * last_day['tf'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the timeseries of the top 5 trending queries for the last day of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_trending(last_day,num_trends):\n",
    "    plot_by_loc=[df_query[df_query['query']==search].resample('1T').count() for search  in  list(last_day.sort_values('tfidf', ascending=False).head(num_trends).index)]\n",
    "    trendings=pd.concat(plot_by_loc,axis=1)\n",
    "    trendings=trendings.resample('1D').sum()\n",
    "    trendings=trendings.fillna(0)\n",
    "    trendings.columns=list(last_day.sort_values('tfidf', ascending=False).head(num_trends).index)\n",
    "    trendings.iplot(subplots=True, shape=(num_trends,1), shared_xaxes=True, fill=True,title='Timeseries of top 5 trending query',yTitle=' ')\n",
    "    \n",
    "plot_trending(last_day,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily see that these are actually queries that are trending on that day, but never on  any of the other days. This seems to be a working approach. However, sometimes trends will be more cyclic, with events happening once in a while. Let's rework a bit the previous bit :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trends_by_day(df_query_perday,date,N,n_previous):\n",
    "    dfs=[]\n",
    "    index_date=df_query_perday.index.get_loc(date)+1\n",
    "    days=df_query_perday.iloc[index_date-n_previous:index_date].index\n",
    "    for day in days:\n",
    "        dfs.append(pd.DataFrame.from_records(df_query_perday.loc[day].counted[0:N],columns=['searchq' ,'count']).set_index('searchq'))\n",
    "    df_days = pd.concat(dfs,axis=1,sort=True)\n",
    "    df_days['idf']=np.log10(len(dfs)/df_days.count(axis='columns'))\n",
    "    # Let's calculate the trending queries of the last day of the data\n",
    "    last_day=dfs[-1] \n",
    "    last_day['tf'] = last_day / last_day.sum() \n",
    "    last_day['idf']=df_days[\"idf\"]\n",
    "    last_day['tfidf'] = last_day['idf'] * last_day['tf'] \n",
    "    \n",
    "    return last_day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the code has been adapted into a function in order to be able to select the trending day of a specific day, compared to a certain number of days before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trends=get_trends_by_day(df_query_perday,\"2018-06-28\",100,7)\n",
    "plot_trending(trends,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By extension, and without requiring a handfull of change, this approach could be used by anytime frame possible : get weekly/monthly new trends, as it just on how we create the \"documents\" based on time resampling. And, in the case of the number of search queries became too high (grouping by month for example), we could easily replace the standard counter by some probabilistic counter, using for example a count-min sketch, in order to still be efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (fastai)",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
